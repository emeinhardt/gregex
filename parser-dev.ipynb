{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:29.934278Z",
     "start_time": "2020-03-30T19:57:29.928823Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Stop!-Grammar-time...\" data-toc-modified-id=\"Stop!-Grammar-time...-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Stop! Grammar time...</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grammar-Notation/NLTK-Demos\" data-toc-modified-id=\"Grammar-Notation/NLTK-Demos-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Grammar Notation/NLTK Demos</a></span></li><li><span><a href=\"#A-grammar-for-a-subset-of-Krambeck-et-al.-2009's-linear-code\" data-toc-modified-id=\"A-grammar-for-a-subset-of-Krambeck-et-al.-2009's-linear-code-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>A grammar for a subset of Krambeck et al. 2009's linear code</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:29.971047Z",
     "start_time": "2020-03-30T19:57:29.938141Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.508408Z",
     "start_time": "2020-03-30T19:57:29.975063Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "from nltk.parse.chart import ChartParser\n",
    "from nltk.parse.chart import SteppingChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.517524Z",
     "start_time": "2020-03-30T19:57:30.512439Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop! Grammar time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Notation/NLTK Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple mathematical/formal context-free grammar of a very simple fragment (subset) of English sentence syntax:\n",
    "\n",
    "`\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> 'the' N | N PP | 'the' N PP\n",
    "VP -> V NP | V PP | V NP PP\n",
    "N -> 'cat'\n",
    "N -> 'dog'\n",
    "N -> 'rug'\n",
    "V -> 'chased'\n",
    "V -> 'sat'\n",
    "P -> 'in'\n",
    "P -> 'on'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.527930Z",
     "start_time": "2020-03-30T19:57:30.521713Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> 'the' N | N PP | 'the' N PP\n",
    "VP -> V NP | V PP | V NP PP\n",
    "N -> 'cat'\n",
    "N -> 'dog'\n",
    "N -> 'rug'\n",
    "V -> 'chased'\n",
    "V -> 'sat'\n",
    "P -> 'in'\n",
    "P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.557088Z",
     "start_time": "2020-03-30T19:57:30.532014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat chased the cat\n",
      "the cat chased the dog\n",
      "the cat chased the rug\n",
      "the cat chased cat in the cat\n",
      "the cat chased cat in the dog\n",
      "the cat chased cat in the rug\n",
      "the cat chased cat in cat in the cat\n",
      "the cat chased cat in cat in the dog\n",
      "the cat chased cat in cat in the rug\n",
      "the cat chased cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the dog\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the rug\n",
      "the cat chased cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in cat in the cat\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(demo_grammar, n=100):\n",
    "    print(str_join(' ', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.564307Z",
     "start_time": "2020-03-30T19:57:30.561110Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_parser = ChartParser(demo_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.577419Z",
     "start_time": "2020-03-30T19:57:30.568395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the (N dog))\n",
      "  (VP (V chased) (NP the (N cat)) (PP (P on) (NP the (N rug)))))\n",
      "(S\n",
      "  (NP the (N dog))\n",
      "  (VP (V chased) (NP the (N cat) (PP (P on) (NP the (N rug))))))\n"
     ]
    }
   ],
   "source": [
    "demo_sentence = 'the dog chased the cat on the rug'\n",
    "\n",
    "for tree in demo_parser.parse(demo_sentence.split()):\n",
    "    print(tree)\n",
    "    if tree is None:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a grammar for a fragment of arithmetic on the integers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "expression -> integer | expression binary_operation expression | '(' expression binary_operation expression ')'\n",
    "binary_operation -> + | - | â¸± | /\n",
    "integer -> (-) natural_number\n",
    "natural_number -> digit | nonzero_digit digit*\n",
    "digit -> 0 | nonzero_digit\n",
    "nonzero_digit -> 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kleene-*, the closely-related + operator, and metalinguistic parentheses for indicating optionality are all [syntactic sugar](https://en.wikipedia.org/wiki/Syntactic_sugar) that can be expressed using more basic rewrite rules. Since `nltk`'s `CFG` module doesn't recognize them, we'll re-express the same more compact grammar noted above without them. (Note also that terminals (= literals) are wrapped in single quotes.)\n",
    "\n",
    "Relevant wikipedia articles:\n",
    " - https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form\n",
    " - https://en.wikipedia.org/wiki/Context-free_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.586072Z",
     "start_time": "2020-03-30T19:57:30.580977Z"
    }
   },
   "outputs": [],
   "source": [
    "arithmetic_grammar = CFG.fromstring(\"\"\"\n",
    "expression -> integer | expression binary_operation expression | '(' expression binary_operation expression ')'\n",
    "binary_operation -> '+' | '-' | 'x' | '/'\n",
    "integer -> natural_number | '-' natural_number\n",
    "natural_number -> digit | nonzero_digit digit_phrase\n",
    "digit_phrase -> digit | digit digit_phrase\n",
    "digit -> '0' | nonzero_digit\n",
    "nonzero_digit -> '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.805878Z",
     "start_time": "2020-03-30T19:57:30.590178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "10000\n",
      "10001\n",
      "10002\n",
      "10003\n",
      "10004\n",
      "10005\n",
      "10006\n",
      "10007\n",
      "10008\n",
      "10009\n",
      "100000\n",
      "100001\n",
      "100002\n",
      "100003\n",
      "100004\n",
      "100005\n",
      "100006\n",
      "100007\n",
      "100008\n",
      "100009\n",
      "1000000\n",
      "1000001\n",
      "1000002\n",
      "1000003\n",
      "1000004\n",
      "1000005\n",
      "1000006\n",
      "1000007\n",
      "1000008\n",
      "1000009\n",
      "10000000\n",
      "10000001\n",
      "10000002\n",
      "10000003\n",
      "10000004\n",
      "10000005\n",
      "10000006\n",
      "10000007\n",
      "10000008\n",
      "10000009\n",
      "100000000\n",
      "100000001\n",
      "100000002\n",
      "100000003\n",
      "100000004\n",
      "100000005\n",
      "100000006\n",
      "100000007\n",
      "100000008\n",
      "100000009\n",
      "1000000000\n",
      "1000000001\n",
      "1000000002\n",
      "1000000003\n",
      "1000000004\n",
      "1000000005\n",
      "1000000006\n",
      "1000000007\n",
      "1000000008\n",
      "1000000009\n"
     ]
    }
   ],
   "source": [
    "for expression in generate(arithmetic_grammar, n=100):\n",
    "    print(str_join('', expression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.812298Z",
     "start_time": "2020-03-30T19:57:30.809452Z"
    }
   },
   "outputs": [],
   "source": [
    "arithmetic_parser = ChartParser(arithmetic_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.821160Z",
     "start_time": "2020-03-30T19:57:30.815690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized = ['1']\n",
      "(expression (integer (natural_number (digit (nonzero_digit 1)))))\n"
     ]
    }
   ],
   "source": [
    "demo_expression = '1'\n",
    "demo_expression_tokenized = demo_expression.split()\n",
    "print('Tokenized = {0}'.format(demo_expression_tokenized))\n",
    "\n",
    "for tree in arithmetic_parser.parse(demo_expression.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.831756Z",
     "start_time": "2020-03-30T19:57:30.824587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized = ['1', '+', '2']\n",
      "(expression\n",
      "  (expression (integer (natural_number (digit (nonzero_digit 1)))))\n",
      "  (binary_operation +)\n",
      "  (expression (integer (natural_number (digit (nonzero_digit 2))))))\n"
     ]
    }
   ],
   "source": [
    "demo_expression = '1 + 2'\n",
    "demo_expression_tokenized = demo_expression.split()\n",
    "print('Tokenized = {0}'.format(demo_expression_tokenized))\n",
    "\n",
    "for tree in arithmetic_parser.parse(demo_expression.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.846667Z",
     "start_time": "2020-03-30T19:57:30.835929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized = ['(', '3', 'x', '2', ')', '+', '3', '/', '4']\n",
      "(expression\n",
      "  (expression\n",
      "    (expression\n",
      "      (\n",
      "      (expression\n",
      "        (integer (natural_number (digit (nonzero_digit 3)))))\n",
      "      (binary_operation x)\n",
      "      (expression\n",
      "        (integer (natural_number (digit (nonzero_digit 2)))))\n",
      "      ))\n",
      "    (binary_operation +)\n",
      "    (expression (integer (natural_number (digit (nonzero_digit 3))))))\n",
      "  (binary_operation /)\n",
      "  (expression (integer (natural_number (digit (nonzero_digit 4))))))\n",
      "(expression\n",
      "  (expression\n",
      "    (\n",
      "    (expression (integer (natural_number (digit (nonzero_digit 3)))))\n",
      "    (binary_operation x)\n",
      "    (expression (integer (natural_number (digit (nonzero_digit 2)))))\n",
      "    ))\n",
      "  (binary_operation +)\n",
      "  (expression\n",
      "    (expression (integer (natural_number (digit (nonzero_digit 3)))))\n",
      "    (binary_operation /)\n",
      "    (expression (integer (natural_number (digit (nonzero_digit 4)))))))\n"
     ]
    }
   ],
   "source": [
    "demo_expression = '( 3 x 2 ) + 3 / 4'\n",
    "demo_expression_tokenized = demo_expression.split()\n",
    "print('Tokenized = {0}'.format(demo_expression_tokenized))\n",
    "\n",
    "for tree in arithmetic_parser.parse(demo_expression.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A grammar for a subset of Krambeck et al. 2009's linear code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is conventional that\n",
    " - linear code be interpreted from right to left (counter to the norm of formal language theory, but not formally unaccommodatable).\n",
    " - the child subtrees of a node be ordered such that the bond locations of the roots of the subtrees descend as you go leftwards among the children.\n",
    " \n",
    "Below is a context-free grammar for a fragment of linear code where each expression describes a single glycan (i.e. no uncertainty operators are expressed):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*wrong*\n",
    "\n",
    "`\n",
    "exp -> stem | exp non_rightmost_branch* stem\n",
    "non_rightmost_branch -> \"(\" exp \")\"\n",
    "stem -> SU_with_bond_info* SU_bare\n",
    "SU_with_bond_info -> SU_bare bond_type bond_location\n",
    "bond_type -> \"a\" | \"b\" | \"?\"\n",
    "bond_location -> \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\" | \"?\"\n",
    "SU_bare -> \"A\" | \"AN\" | \"B\" | \"E\" | \"F\" | \"G\" | \"GN\" | \"G[Q]\" | \"H\" | \"H[2Q, 4Q]\" | \"I\" | \"K\" | \"L\" | \"M\" | \"NG\" | \"NJ\" | \"NN\" | \"NN[9N]\" | \"N[5Q]\" | \"O\" | \"P\" | \"PH\" | \"R\" | \"S\" | \"U\" | \"W\" | \"X\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "exp -> empty | stem | subexp non_rightmost_branch+ stem\n",
    "stem -> SU_with_bond_info* SU_bare\n",
    "non_rightmost_branch -> \"(\" subexp \")\"\n",
    "subexp -> substem | subexp non_rightmost_branch+ substem\n",
    "substem -> SU_with_bond_info+\n",
    "SU_with_bond_info -> SU_bare bond_type bond_location\n",
    "bond_type -> \"a\" | \"b\" | \"?\"\n",
    "bond_location -> \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\" | \"?\"\n",
    "SU_bare -> \"A\" | \"AN\" | \"B\" | \"E\" | \"F\" | \"G\" | \"GN\" | \"G[Q]\" | \"H\" | \"H[2Q, 4Q]\" | \"I\" | \"K\" | \"L\" | \"M\" | \"NG\" | \"NJ\" | \"NN\" | \"NN[9N]\" | \"N[5Q]\" | \"O\" | \"P\" | \"PH\" | \"R\" | \"S\" | \"U\" | \"W\" | \"X\"\n",
    "empty -> \"\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...where\n",
    " - `->`, `|`, `*`, `+` are all metalinguistic operators with their usual formal-language theoretic meaning (see any textbook or introductory material).\n",
    " - all terminal symbols are quoted string literals.\n",
    " - the enumeration of saccharide units is cribbed from a relatively arbitrary mix of what `glypy` supports and what `glymmer` supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.857205Z",
     "start_time": "2020-03-30T19:57:30.849981Z"
    }
   },
   "outputs": [],
   "source": [
    "#right-to-left leftwards-descending uncertainty-operator-free normal form...\n",
    "# ...formatted in a way that NLTK understands = with no Kleene star or plus, but\n",
    "# simulating Kleene stars/pluses using left-recursive rules\n",
    "RTF_LDNF_UOF_g = CFG.fromstring(\"\"\"\n",
    "    exp -> empty | stem | subexp non_rightmost_branch_phrase stem\n",
    "    stem -> SU_with_bond_info_phrase_star SU_bare\n",
    "    non_rightmost_branch_phrase -> empty | non_rightmost_branch_phrase non_rightmost_branch\n",
    "    non_rightmost_branch -> '(' subexp ')'\n",
    "    subexp -> substem | subexp non_rightmost_branch_phrase substem\n",
    "    substem -> SU_with_bond_info_phrase_plus\n",
    "    SU_with_bond_info_phrase_star -> empty | SU_with_bond_info | SU_with_bond_info_phrase_star SU_with_bond_info\n",
    "    SU_with_bond_info_phrase_plus -> SU_with_bond_info | SU_with_bond_info_phrase_star SU_with_bond_info\n",
    "    SU_with_bond_info -> SU_bare bond_type bond_location\n",
    "    bond_type -> 'a' | 'b' | '?'\n",
    "    bond_location -> '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '?'\n",
    "    SU_bare -> 'A' | 'AN' | 'B' | 'E' | 'F' | 'G' | 'GN' | 'G[Q]' | 'H' | 'H[2Q, 4Q]' | 'I' | 'K' | 'L' | 'M' | 'NG' | 'NJ' | 'NN' | 'NN[9N]' | 'N[5Q]' | 'O' | 'P' | 'PH' | 'R' | 'S' | 'U' | 'W' | 'X'\n",
    "    empty -> \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.865308Z",
     "start_time": "2020-03-30T19:57:30.861136Z"
    }
   },
   "outputs": [],
   "source": [
    "# current grammar generates a recursion error, but that's not a sign the \n",
    "# current grammar is incorrect.\n",
    "# for lce in generate(RTF_LDNF_UOF_g, n=10000):\n",
    "#     print(str_join(' ', lce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.873284Z",
     "start_time": "2020-03-30T19:57:30.869114Z"
    }
   },
   "outputs": [],
   "source": [
    "RTF_LDNF_UOF_parser = ChartParser(RTF_LDNF_UOF_g)\n",
    "RTF_LDNF_UOF_parser_step = SteppingChartParser(RTF_LDNF_UOF_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.901537Z",
     "start_time": "2020-03-30T19:57:30.877012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exp (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "-------\n",
      "(exp\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info (SU_bare M) (bond_type a) (bond_location 6)))\n",
      "    (SU_bare M)))\n",
      "(exp\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info_phrase_star (empty ))\n",
      "      (SU_with_bond_info (SU_bare M) (bond_type a) (bond_location 6)))\n",
      "    (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase (empty ))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase (empty ))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "-------\n",
      "-------\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info_phrase_star (empty ))\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info_phrase_star (empty ))\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for tree in RTF_LDNF_UOF_parser.parse(['M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser.parse(['M', 'a', '6', 'M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser.parse(['(', 'M', 'a', '6', ')', 'M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser.parse(['M', 'a', '4', '(', 'M', 'a', '6', ')', 'M']):\n",
    "    print(tree)\n",
    "print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.909838Z",
     "start_time": "2020-03-30T19:57:30.904937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for tree in RTF_LDNF_UOF_parser_step.parse(['M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser_step.parse(['M', 'a', '6', 'M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser_step.parse(['(', 'M', 'a', '6', ')', 'M']):\n",
    "    print(tree)\n",
    "print('-------')\n",
    "\n",
    "for tree in RTF_LDNF_UOF_parser_step.parse(['M', 'a', '4', '(', 'M', 'a', '6', ')', 'M']):\n",
    "    print(tree)\n",
    "print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.922681Z",
     "start_time": "2020-03-30T19:57:30.913867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN'], ['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN'], ['G', 'a', '3', 'M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN']]\n"
     ]
    }
   ],
   "source": [
    "#Krambeck et al. 2009, Fig. 1\n",
    "Kea2009Fig1 = [\n",
    "    'Ma2Ma2Ma3(Ma2Ma3(Ma2Ma6)Ma6)Mb4GNb4GN',\n",
    "    'Ma2Ma2Ma3(Ma3(Ma2Ma6)Ma6)Mb4GNb4GN',\n",
    "    'Ga3Ma2Ma2Ma3(Ma2Ma3(Ma2Ma6)Ma6)Mb4GNb4GN']\n",
    "\n",
    "Kea2009Fig1_tokenized = [['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN'],\n",
    "                         ['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN'],\n",
    "                         ['G', 'a', '3', 'M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN']]\n",
    "print(Kea2009Fig1_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.932001Z",
     "start_time": "2020-03-30T19:57:30.926749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN']\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "first = ['M', 'a', '2', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '3', '(', 'M', 'a', '2', 'M', 'a', '6', ')', 'M', 'a', '6', ')', 'M', 'b', '4', 'GN', 'b', '4', 'GN']\n",
    "print(first)\n",
    "print(len(first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:57:30.957351Z",
     "start_time": "2020-03-30T19:57:30.935095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GN', 'b', '4', 'GN']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exp\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info\n",
      "        (SU_bare GN)\n",
      "        (bond_type b)\n",
      "        (bond_location 4)))\n",
      "    (SU_bare GN)))\n",
      "(exp\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info_phrase_star (empty ))\n",
      "      (SU_with_bond_info\n",
      "        (SU_bare GN)\n",
      "        (bond_type b)\n",
      "        (bond_location 4)))\n",
      "    (SU_bare GN)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare GN)\n",
      "          (bond_type b)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase (empty ))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare GN)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare GN)\n",
      "          (bond_type b)\n",
      "          (bond_location 4)))))\n",
      "  (non_rightmost_branch_phrase (empty ))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare GN)))\n"
     ]
    }
   ],
   "source": [
    "first[-4:]\n",
    "for tree in RTF_LDNF_UOF_parser.parse(first[-4:]):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:58:15.389034Z",
     "start_time": "2020-03-30T19:57:30.960968Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(35):\n",
    "#     print(i)\n",
    "#     print(first[-i:])\n",
    "#     for tree in RTF_LDNF_UOF_parser.parse(first[-i:]):\n",
    "#         print(tree)\n",
    "#     print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:00:36.911645Z",
     "start_time": "2020-03-30T19:58:15.393286Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each, each_tokenized in zip(Kea2009Fig1, Kea2009Fig1_tokenized):\n",
    "#     print('Linear code expression, pre-tokenized = \\n{0}'.format(each))\n",
    "\n",
    "#     for tree in RTF_LDNF_UOF_parser.parse(each_tokenized):\n",
    "#         print(tree)\n",
    "#     print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:56.687054Z",
     "start_time": "2020-03-30T20:00:36.915267Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each, each_tokenized in zip(Kea2009Fig1, Kea2009Fig1_tokenized):\n",
    "#     print('Linear code expression, pre-tokenized = \\n{0}'.format(each))\n",
    "\n",
    "#     for tree in RTF_LDNF_UOF_parser.parse(each_tokenized):\n",
    "#         print(tree)\n",
    "#     print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.060498Z",
     "start_time": "2020-03-30T20:02:56.690898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear code expression, pre-tokenized = \n",
      "Ma2Ma2Ma3(Ma2Ma3(Ma2Ma6)Ma6)Mb4GNb4GN\n",
      "15552\n",
      "---------------------\n",
      "Linear code expression, pre-tokenized = \n",
      "Ma2Ma2Ma3(Ma3(Ma2Ma6)Ma6)Mb4GNb4GN\n",
      "5184\n",
      "---------------------\n",
      "Linear code expression, pre-tokenized = \n",
      "Ga3Ma2Ma2Ma3(Ma2Ma3(Ma2Ma6)Ma6)Mb4GNb4GN\n",
      "46656\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for each, each_tokenized in zip(Kea2009Fig1, Kea2009Fig1_tokenized):\n",
    "    print('Linear code expression, pre-tokenized = \\n{0}'.format(each))\n",
    "\n",
    "    print(len(list(RTF_LDNF_UOF_parser.parse(each_tokenized))))\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.177834Z",
     "start_time": "2020-03-30T20:02:57.063849Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear code expression, pre-tokenized = \n",
      "Ma2Ma2Ma3(Ma2Ma3(Ma2Ma6)Ma6)Mb4GNb4GN\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "parse_trees = []\n",
    "for each, each_tokenized in [zip(Kea2009Fig1, Kea2009Fig1_tokenized)[0]]:\n",
    "    print('Linear code expression, pre-tokenized = \\n{0}'.format(each))\n",
    "\n",
    "    for tree in RTF_LDNF_UOF_parser.parse(each_tokenized):\n",
    "        parse_trees.append(tree)\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.187802Z",
     "start_time": "2020-03-30T20:02:57.181235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15552"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parse_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.197756Z",
     "start_time": "2020-03-30T20:02:57.191614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star\n",
      "          (SU_with_bond_info_phrase_star\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 2)))\n",
      "          (SU_with_bond_info\n",
      "            (SU_bare M)\n",
      "            (bond_type a)\n",
      "            (bond_location 2)))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 3)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (subexp\n",
      "          (substem\n",
      "            (SU_with_bond_info_phrase_plus\n",
      "              (SU_with_bond_info_phrase_star\n",
      "                (SU_with_bond_info\n",
      "                  (SU_bare M)\n",
      "                  (bond_type a)\n",
      "                  (bond_location 2)))\n",
      "              (SU_with_bond_info\n",
      "                (SU_bare M)\n",
      "                (bond_type a)\n",
      "                (bond_location 3)))))\n",
      "        (non_rightmost_branch_phrase\n",
      "          (non_rightmost_branch_phrase (empty ))\n",
      "          (non_rightmost_branch\n",
      "            (\n",
      "            (subexp\n",
      "              (substem\n",
      "                (SU_with_bond_info_phrase_plus\n",
      "                  (SU_with_bond_info_phrase_star\n",
      "                    (SU_with_bond_info\n",
      "                      (SU_bare M)\n",
      "                      (bond_type a)\n",
      "                      (bond_location 2)))\n",
      "                  (SU_with_bond_info\n",
      "                    (SU_bare M)\n",
      "                    (bond_type a)\n",
      "                    (bond_location 6)))))\n",
      "            )))\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info_phrase_star\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type b)\n",
      "          (bond_location 4)))\n",
      "      (SU_with_bond_info\n",
      "        (SU_bare GN)\n",
      "        (bond_type b)\n",
      "        (bond_location 4)))\n",
      "    (SU_bare GN)))\n"
     ]
    }
   ],
   "source": [
    "print(parse_trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.207439Z",
     "start_time": "2020-03-30T20:02:57.201357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star\n",
      "          (SU_with_bond_info_phrase_star\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 2)))\n",
      "          (SU_with_bond_info\n",
      "            (SU_bare M)\n",
      "            (bond_type a)\n",
      "            (bond_location 2)))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 3)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (subexp\n",
      "          (substem\n",
      "            (SU_with_bond_info_phrase_plus\n",
      "              (SU_with_bond_info_phrase_star\n",
      "                (SU_with_bond_info\n",
      "                  (SU_bare M)\n",
      "                  (bond_type a)\n",
      "                  (bond_location 2)))\n",
      "              (SU_with_bond_info\n",
      "                (SU_bare M)\n",
      "                (bond_type a)\n",
      "                (bond_location 3)))))\n",
      "        (non_rightmost_branch_phrase\n",
      "          (non_rightmost_branch_phrase (empty ))\n",
      "          (non_rightmost_branch\n",
      "            (\n",
      "            (subexp\n",
      "              (substem\n",
      "                (SU_with_bond_info_phrase_plus\n",
      "                  (SU_with_bond_info_phrase_star\n",
      "                    (SU_with_bond_info\n",
      "                      (SU_bare M)\n",
      "                      (bond_type a)\n",
      "                      (bond_location 2)))\n",
      "                  (SU_with_bond_info\n",
      "                    (SU_bare M)\n",
      "                    (bond_type a)\n",
      "                    (bond_location 6)))))\n",
      "            )))\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 6)))))\n",
      "      )))\n",
      "  (stem\n",
      "    (SU_with_bond_info_phrase_star\n",
      "      (SU_with_bond_info_phrase_star\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type b)\n",
      "          (bond_location 4)))\n",
      "      (SU_with_bond_info\n",
      "        (SU_bare GN)\n",
      "        (bond_type b)\n",
      "        (bond_location 4)))\n",
      "    (SU_bare GN)))\n"
     ]
    }
   ],
   "source": [
    "print(parse_trees[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.224338Z",
     "start_time": "2020-03-30T20:02:57.211081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 4)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info_phrase_star (empty ))\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 4)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 4)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n",
      "(exp\n",
      "  (subexp\n",
      "    (substem\n",
      "      (SU_with_bond_info_phrase_plus\n",
      "        (SU_with_bond_info_phrase_star (empty ))\n",
      "        (SU_with_bond_info\n",
      "          (SU_bare M)\n",
      "          (bond_type a)\n",
      "          (bond_location 6)))))\n",
      "  (non_rightmost_branch_phrase\n",
      "    (non_rightmost_branch_phrase (empty ))\n",
      "    (non_rightmost_branch\n",
      "      (\n",
      "      (subexp\n",
      "        (substem\n",
      "          (SU_with_bond_info_phrase_plus\n",
      "            (SU_with_bond_info_phrase_star (empty ))\n",
      "            (SU_with_bond_info\n",
      "              (SU_bare M)\n",
      "              (bond_type a)\n",
      "              (bond_location 4)))))\n",
      "      )))\n",
      "  (stem (SU_with_bond_info_phrase_star (empty )) (SU_bare M)))\n"
     ]
    }
   ],
   "source": [
    "for tree in RTF_LDNF_UOF_parser.parse(['M', 'a', '6', '(', 'M', 'a', '4', ')', 'M']):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:02:57.231353Z",
     "start_time": "2020-03-30T20:02:57.227580Z"
    }
   },
   "outputs": [],
   "source": [
    "# monster = 'NNa6Ab4GNb4(NNa3(ANb4)Ab4GNb2)Ma3(NNa3(ANb4)Ab4GNb3Ab4GNb2(NNa3(ANb4)Ab4GNb6)Ma6)Ma4GNb4(Fa6)GNb'\n",
    "# monster_tokenized = ['NN', 'a', '6', 'A', 'b', '4', 'GN', 'b', '4', '(', 'NN', 'a', '3', '(', 'AN', 'b', '4', ')', 'A', 'b', '4', 'GN', 'b', '2', ')', 'M', 'a', '3', '(', 'NN', 'a', '3', '(', 'AN', 'b', '4', ')', 'A', 'b', '4', 'GN', 'b', '3', 'A', 'b', '4', 'GN', 'b', '2', '(', 'NN', 'a', '3', '(', 'AN', 'b', '4', ')', 'A', 'b', '4', 'GN', 'b', '6', ')', 'M', 'a', '6', ')', 'M', 'a', '4', 'GN', 'b', '4', '(', 'F', 'a', '6', ')', 'GN']\n",
    "# # for tree in RTF_LDNF_UOF_parser.parse(monster_tokenized):\n",
    "# #     print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
